---
title: "Why Is Spatially Explicit Discretization Necessary?"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{whysed}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---




We use simulated data comprising 225 cells organized in a 15-row by 15-column grid to illustrate the rationale for employing spatially explicit discretization methods. We pre-constructed a grid-based simulated dataset with three strata, and then simulated Y under different spatial autocorrelation scenarios to explore the differences between explicit spatial discretization and implicit spatial discretization. The simulation of spatial data is conducted using the `spdgp` package in R. We selected hierarchical clustering with spatial constraints and hierarchical clustering method to represent explicit and implicit spatial discretization, respectively. The hierarchical clustering with spatial constraints and hierarchical clustering methods were implemented using the `ClustGeo` package. In subsequent analyses, all discretization methods applied will discretize the dataset into three strata for the calculation of the q-values.

## Install Necessary R Packages

```r
install.packages(c("sf","terra","sdsfun","gdverse"),dep = TRUE)
# install.packages("devtools")
devtools::install_github("ausgis/sesp",build_vignettes = TRUE,dep = TRUE)
# install.packages("pak")
pak::pak("josiahparry/spdgp")
```

## Simulated Independent Strata X


``` r
m = matrix(2,nrow = 15, ncol = 15)
zone1_indice = c(6:9,seq(8,by = -1,length.out = 6))
for (i in seq_along(zone1_indice)) {
  m[seq(1,zone1_indice[i]),i] = 1
}
m[,11:15] = 3
m[13,11] = 2
m[14,11:12] = 2
m[15,11:13] = 2

library(sf)
library(terra)
r = terra::rast(m, crs = "EPSG:4326")
names(r) = 'simx_strata'
simx = sf::st_as_sf(terra::as.points(r))
simx
## Simple feature collection with 225 features and 1 field
## Geometry type: POINT
## Dimension:     XY
## Bounding box:  xmin: 0.5 ymin: 0.5 xmax: 14.5 ymax: 14.5
## Geodetic CRS:  WGS 84
## First 10 features:
##    simx_strata         geometry
## 1            1 POINT (0.5 14.5)
## 2            1 POINT (1.5 14.5)
## 3            1 POINT (2.5 14.5)
## 4            1 POINT (3.5 14.5)
## 5            1 POINT (4.5 14.5)
## 6            1 POINT (5.5 14.5)
## 7            1 POINT (6.5 14.5)
## 8            1 POINT (7.5 14.5)
## 9            1 POINT (8.5 14.5)
## 10           1 POINT (9.5 14.5)

strata1 = tibble::tibble(
  x = c(0,0,3.5,10,10),
  y = c(15,9.5,6,12.5,15)
) |>
  sf::st_as_sf(coords = c("x","y"), crs = 4326) |>
  sf::st_combine() |>
  sf::st_cast("POLYGON")

strata2 = tibble::tibble(
  x = c(0,0,3.5,10,10,13.5),
  y = c(0,9.5,6,12.5,3.5,0)
) |>
  sf::st_as_sf(coords = c("x","y"), crs = 4326) |>
  sf::st_combine() |>
  sf::st_cast("POLYGON")

strata3 = tibble::tibble(
  x = c(15,15,10,10,13.5),
  y = c(0,15,15,3.5,0)
) |>
  sf::st_as_sf(coords = c("x","y"), crs = 4326) |>
  sf::st_combine() |>
  sf::st_cast("POLYGON")

strata = sf::st_sf(stratas = c(1,2,3),
                   geometry = do.call(c, list(strata1,strata2,strata3)))

ggplot2::ggplot() +
  ggplot2::geom_sf(data = strata, fill = 'transparent',
                   color = 'grey10', lwd = 0.75) +
  ggplot2::geom_sf(data = simx,
                   ggplot2::aes(color = factor(simx_strata))) +
  ggplot2::labs(color = 'Strata') +
  ggplot2::theme_void()
```

![**Figure 1**. Strata of simulated independent variable X](man/figures/whysed/x_strata-1.png)

## A Monte Carlo simulation experiment demonstrating the necessity of spatial explicit discretization

The error term is specified as $\mu \sim \mathcal{N}(0, 0.1)$, and the corresponding $Y$ is simulated using the Spatially Lagged X Error Process. The spatial lag coefficients of the error terms are set to twice the stratification levels, i.e., stratifications 1, 2, and 3 correspond to spatial lag coefficients of 2, 4, and 6, respectively. The autoregressive coefficients take values from 0.05 to 0.95 with an interval of 0.05. For each spatial autoregressive coefficient $\lambda$, we randomly simulate 1000 times.


``` r
lambda = seq(0.05,0.95,by = 0.05)

lw = spdep::nb2listw(sdsfun::spdep_nb(simx),
                     style = "W",
                     zero.policy = TRUE)
```


``` r
mc_simq = \(cores = 6){
  doclust = FALSE
  if (inherits(cores, "cluster")) {
    doclust = TRUE
  } else if (cores > 1) {
    doclust = TRUE
    cores = parallel::makeCluster(cores)
    on.exit(parallel::stopCluster(cores), add = TRUE)
  }

  gdist = stats::as.dist(sdsfun::sf_distance_matrix(simx))
  hclustgeo_disc = \(xv,alpha = 0.5){
    D0 = stats::dist(xv)
    resh = ClustGeo::hclustgeo(D0,gdist,alpha = alpha)
    return(stats::cutree(resh,3))
  }

  calcul_q = \(lambdav){
    u = rnorm(nrow(simx),0,0.1)
    y = spdgp::sim_slx_error(u, simx$simx_strata, simx$simx_strata*2,
                             lw, lambda = lambdav)
    sed = hclustgeo_disc(y,alpha = 0.75)
    sid = hclustgeo_disc(y,alpha = 0)
    qv1 = gdverse::factor_detector(y,sed)[[1]]
    qv2 = gdverse::factor_detector(y,sid)[[1]]
    res = tibble::tibble(qv_sed = qv1, qv_sid = qv2,
                         qv_bias = qv1 - qv2,
                         lambda = lambdav)
    return(res)
  }

  if (doclust) {
    parallel::clusterExport(cores, varlist = c("simx","lambda","lw"))
    out_g = parallel::parLapply(cores,lambda,calcul_q)
    out_g = tibble::as_tibble(do.call(rbind, out_g))
  } else {
    out_g = purrr::map_dfr(lambda,calcul_q)
  }
  return(out_g)
}

qv = mc_simq(cores = 12)
qv
## # A tibble: 19 Ã— 4
##    qv_sed qv_sid qv_bias lambda
##     <dbl>  <dbl>   <dbl>  <dbl>
##  1  0.998  0.998       0   0.05
##  2  0.998  0.998       0   0.1 
##  3  0.998  0.998       0   0.15
##  4  0.998  0.998       0   0.2 
##  5  0.998  0.998       0   0.25
##  6  0.998  0.998       0   0.3 
##  7  0.998  0.998       0   0.35
##  8  0.998  0.998       0   0.4 
##  9  0.998  0.998       0   0.45
## 10  0.998  0.998       0   0.5 
## 11  0.998  0.998       0   0.55
## 12  0.998  0.998       0   0.6 
## 13  0.996  0.996       0   0.65
## 14  0.997  0.997       0   0.7 
## 15  0.996  0.996       0   0.75
## 16  0.994  0.994       0   0.8 
## 17  0.996  0.996       0   0.85
## 18  0.993  0.993       0   0.9 
## 19  0.994  0.994       0   0.95
tapply(qv$qv_bias, qv$lambda, mean)
## 0.05  0.1 0.15  0.2 0.25  0.3 0.35  0.4 0.45  0.5 0.55  0.6 0.65  0.7 0.75  0.8 0.85  0.9 0.95 
##    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0    0
```
